{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "encoder_decoder final.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OptrqXwlvEJF"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQsbHHlhvEJG",
        "outputId": "1019b7de-171e-4391-a5db-0cf8f39f0d0b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rXfzxBFvEJH"
      },
      "source": [
        "lines=pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\",dtype={'english_sentence': object,'hindi_sentence':object})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsF21-BEvEJH",
        "outputId": "4fdb9049-391e-4020-aeec-0dbac9deadcb"
      },
      "source": [
        "lines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127602</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>Examples of art deco construction can be found...</td>\n",
              "      <td>आर्ट डेको शैली के निर्माण मैरीन ड्राइव और ओवल ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127603</th>\n",
              "      <td>ted</td>\n",
              "      <td>and put it in our cheeks.</td>\n",
              "      <td>और अपने गालों में डाल लेते हैं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127604</th>\n",
              "      <td>tides</td>\n",
              "      <td>As for the other derivatives of sulphur , the ...</td>\n",
              "      <td>जहां तक गंधक के अन्य उत्पादों का प्रश्न है , द...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127605</th>\n",
              "      <td>tides</td>\n",
              "      <td>its complicated functioning is defined thus in...</td>\n",
              "      <td>Zरचना-प्रकिया को उसने एक पहेली में यों बांधा है .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127606</th>\n",
              "      <td>ted</td>\n",
              "      <td>They've just won four government contracts to ...</td>\n",
              "      <td>हाल ही में उन्हें सरकारी ठेका मिला है करीब सौ ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>127607 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           source                                   english_sentence  \\\n",
              "0             ted  politicians do not have permission to do what ...   \n",
              "1             ted         I'd like to tell you about one such child,   \n",
              "2       indic2012  This percentage is even greater than the perce...   \n",
              "3             ted  what we really mean is that they're bad at not...   \n",
              "4       indic2012  .The ending portion of these Vedas is called U...   \n",
              "...           ...                                                ...   \n",
              "127602  indic2012  Examples of art deco construction can be found...   \n",
              "127603        ted                          and put it in our cheeks.   \n",
              "127604      tides  As for the other derivatives of sulphur , the ...   \n",
              "127605      tides  its complicated functioning is defined thus in...   \n",
              "127606        ted  They've just won four government contracts to ...   \n",
              "\n",
              "                                           hindi_sentence  \n",
              "0       राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1       मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "2        यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
              "3          हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "4             इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n",
              "...                                                   ...  \n",
              "127602  आर्ट डेको शैली के निर्माण मैरीन ड्राइव और ओवल ...  \n",
              "127603                    और अपने गालों में डाल लेते हैं।  \n",
              "127604  जहां तक गंधक के अन्य उत्पादों का प्रश्न है , द...  \n",
              "127605  Zरचना-प्रकिया को उसने एक पहेली में यों बांधा है .  \n",
              "127606  हाल ही में उन्हें सरकारी ठेका मिला है करीब सौ ...  \n",
              "\n",
              "[127607 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUHsyTF8vEJI"
      },
      "source": [
        "lines=lines[~pd.isnull(lines['english_sentence'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oftGowctvEJI",
        "outputId": "f35af3fc-1664-46d1-c14a-9c86e9d1c1b4"
      },
      "source": [
        "lines.drop_duplicates(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFkVd3nOvEJI",
        "outputId": "f4ae71ca-4842-48ec-9a02-5b823531f9a4"
      },
      "source": [
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "597czs3lvEJI"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y288MdlOvEJI"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy1VAv-evEJI",
        "outputId": "6b6b5270-24c8-4d69-9690-843506545783"
      },
      "source": [
        "from tqdm import tqdm\n",
        "preprocessed_reviews = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(lines['english_sentence'].values):\n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "# https://gist.github.com/sebleier/554280\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stop_words) \n",
        "    preprocessed_reviews.append(sentance.strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 124827/124827 [00:03<00:00, 41076.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr8omx96vEJI",
        "outputId": "d1de7192-e186-4be0-cf4b-7f8593d26be7"
      },
      "source": [
        "lines['English_cleanedText']=preprocessed_reviews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU4-7zCevEJJ"
      },
      "source": [
        "exclude = set(string.punctuation)\n",
        "remove_digits = str.maketrans('', '', digits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J6jk5KmvEJJ"
      },
      "source": [
        "h_sentance=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "h_sentance=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "h_sentance=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "h_sentance = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "h_sentance=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
        "h_sentance=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYsplo0WvEJJ",
        "outputId": "b651d3b6-5fc0-4448-ac0e-d837e317b8ed"
      },
      "source": [
        "lines['Hindi_cleanedText']=h_sentance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0SfVeKMvEJJ"
      },
      "source": [
        "english=lines['English_cleanedText']\n",
        "english_70k=english[:1000]\n",
        "hindi=lines['Hindi_cleanedText']\n",
        "hindi_70k=hindi[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFiRvS_ivEJJ",
        "outputId": "7d4d8f6e-f321-4274-a505-b25696a93b2b"
      },
      "source": [
        "import collections\n",
        "\n",
        "english_words_counter = collections.Counter([word for sentence in english_70k for word in sentence.split()])\n",
        "hindi_words_counter = collections.Counter([word for sentence in hindi_70k for word in sentence.split()])\n",
        "\n",
        "print('{} English words.'.format(len([word for sentence in english_70k for word in sentence.split()])))\n",
        "print('{} unique English words.'.format(len(english_words_counter)))\n",
        "print('10 Most common words in the English dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print('{} hindi words.'.format(len([word for sentence in hindi_70k for word in sentence.split()])))\n",
        "print('{} unique hindi words.'.format(len(hindi_words_counter)))\n",
        "print('10 Most common words in the hindi dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*hindi_words_counter.most_common(10)))[0]) + '\"')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8252 English words.\n",
            "4275 unique English words.\n",
            "10 Most common words in the English dataset:\n",
            "\"one\" \"india\" \"also\" \"world\" \"people\" \"time\" \"made\" \"first\" \"government\" \"like\"\n",
            "\n",
            "19079 hindi words.\n",
            "5546 unique hindi words.\n",
            "10 Most common words in the hindi dataset:\n",
            "\"के\" \"में\" \"है\" \"की\" \".\" \"और\" \"से\" \"का\" \"को\" \",\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWSLzFnbvEJJ"
      },
      "source": [
        "import project_tests as tests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddTOrntqYu5A"
      },
      "source": [
        "def test_encdec_model(encdec_model):\n",
        "    input_shape = (1000, 220, 1)\n",
        "    output_sequence_length = 220\n",
        "    english_vocab_size = 4275\n",
        "    hindi_vocab_size = 5324\n",
        "\n",
        "    model = encdec_model(input_shape, output_sequence_length, english_vocab_size, hindi_vocab_size)\n",
        "    _test_model(model, input_shape, output_sequence_length, hindi_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJuaBYPzvEJJ"
      },
      "source": [
        "def tokenize(x):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(x)\n",
        "    return tokenizer.texts_to_sequences(x), tokenizer\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohVV7TcavEJJ"
      },
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import project_tests as tests\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy,binary_crossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KE1R7CNpYqg"
      },
      "source": [
        "def tokenize(x):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(x)\n",
        "    return tokenizer.texts_to_sequences(x), tokenizer\n",
        "\n",
        "tests.test_tokenize(tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJK9SDKFvEJJ",
        "outputId": "7d699254-9495-4f83-f7c9-bc177a614f22"
      },
      "source": [
        "def pad(x, length=None):\n",
        "   \n",
        "    return pad_sequences(x, maxlen=length, padding='post')\n",
        "\n",
        "tests.test_pad(pad)\n",
        "\n",
        "\n",
        "test_pad = pad(text_tokenized)\n",
        "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(np.array(token_sent)))\n",
        "    print('  Output: {}'.format(pad_sent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 1 in x\n",
            "  Input:  [1 2 4 5 6 7 1 8 9]\n",
            "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
            "Sequence 2 in x\n",
            "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
            "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
            "Sequence 3 in x\n",
            "  Input:  [18 19  3 20 21]\n",
            "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dPC8ZXzvEJJ",
        "outputId": "70443999-5837-47c4-960c-d111bcc8041c"
      },
      "source": [
        "def preprocess(x, y):\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    \n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
        "\n",
        "preproc_english_sentences, preproc_hindi_sentences, english_tokenizer, hindi_tokenizer =\\\n",
        "    preprocess(english_70k, hindi_70k)\n",
        "    \n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_hindi_sequence_length = preproc_hindi_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "hindi_vocab_size = len(hindi_tokenizer.word_index)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max Hindi sentence length:\", max_hindi_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"Hindi vocabulary size:\", hindi_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 71\n",
            "Max Hindi sentence length: 220\n",
            "English vocabulary size: 4275\n",
            "Hindi vocabulary size: 5324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9kZHFo4vEJK",
        "outputId": "a7f71c5d-1ecc-421a-fa75-3229aa0a38c5"
      },
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
        "\n",
        "print('`logits_to_text` function loaded.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`logits_to_text` function loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TZtkYpavEJK",
        "outputId": "8ae02551-7967-4c29-a9c1-67de4847bb7c"
      },
      "source": [
        "tmp_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 220, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2OqjLArvEJK",
        "outputId": "cc26ccb6-f65d-46d1-dce6-6f34d7fcad7a"
      },
      "source": [
        "def encdec_model(input_shape, output_sequence_length, english_vocab_size, hindi_vocab_size):\n",
        "   \n",
        "    learning_rate = 0.005\n",
        "    \n",
        "        \n",
        "    model = Sequential()\n",
        "    # Encoder\n",
        "    model.add(GRU(64, input_shape=input_shape[1:], go_backwards=True))\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    # Decoder\n",
        "    model.add(GRU(98, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(156, activation='relu')))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(TimeDistributed(Dense(hindi_vocab_size, activation='softmax')))\n",
        "\n",
        "    \n",
        "    model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(learning_rate),metrics=['accuracy'])\n",
        "                  \n",
        "                  \n",
        "    \n",
        "    return model\n",
        "\n",
        "tests.test_encdec_model(encdec_model)\n",
        "\n",
        "\n",
        "tmp_x = pad(preproc_english_sentences, preproc_hindi_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_hindi_sentences.shape[-2], 1))\n",
        "\n",
        "\n",
        "encdec_rnn_model = encdec_model(tmp_x.shape,preproc_hindi_sentences.shape[1],len(english_tokenizer.word_index)+1,len(hindi_tokenizer.word_index)+1)\n",
        "\n",
        "encdec_rnn_model.summary()\n",
        "\n",
        "encdec_rnn_model.fit(tmp_x, preproc_hindi_sentences, batch_size=150, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_7 (GRU)                  (None, 56)                9744      \n",
            "_________________________________________________________________\n",
            "repeat_vector_4 (RepeatVecto (None, 220, 56)           0         \n",
            "_________________________________________________________________\n",
            "gru_8 (GRU)                  (None, 220, 128)          71040     \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 220, 256)          33024     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 220, 256)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 220, 5325)         1368525   \n",
            "=================================================================\n",
            "Total params: 1,482,333\n",
            "Trainable params: 1,482,333\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 800 samples, validate on 200 samples\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 47s 59ms/step - loss: 8.1170 - acc: 0.4938 - val_loss: 7.0261 - val_acc: 0.9144\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 47s 59ms/step - loss: 5.7984 - acc: 0.9157 - val_loss: 3.0739 - val_acc: 0.9144\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 48s 60ms/step - loss: 1.7866 - acc: 0.9157 - val_loss: 0.9601 - val_acc: 0.9144\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 55s 69ms/step - loss: 1.0453 - acc: 0.9157 - val_loss: 1.1576 - val_acc: 0.9144\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 50s 63ms/step - loss: 1.1311 - acc: 0.9157 - val_loss: 1.1324 - val_acc: 0.9144\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 46s 57ms/step - loss: 1.0658 - acc: 0.9157 - val_loss: 1.0073 - val_acc: 0.9144\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 45s 56ms/step - loss: 0.9331 - acc: 0.9157 - val_loss: 0.8823 - val_acc: 0.9144\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 45s 56ms/step - loss: 0.8707 - acc: 0.9157 - val_loss: 0.8263 - val_acc: 0.9144\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 45s 57ms/step - loss: 0.8159 - acc: 0.9157 - val_loss: 0.8066 - val_acc: 0.9144\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 46s 58ms/step - loss: 0.7955 - acc: 0.9157 - val_loss: 0.7934 - val_acc: 0.9144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc14d49b3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJDdOdZIvEJK",
        "outputId": "4c7925d0-f931-4b4d-eb43-9b358021e062"
      },
      "source": [
        "print(\"Prediction:\")\n",
        "print(logits_to_text(encdec_rnn_model.predict(tmp_x[:1])[0], hindi_tokenizer))\n",
        "\n",
        "print(\"\\nCorrect Translation:\")\n",
        "print(hindi_70k[:1])\n",
        "\n",
        "print(\"\\nOriginal text:\")\n",
        "print(english_70k[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction:\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Correct Translation:\n",
            "0    राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...\n",
            "Name: Hindi_cleanedText, dtype: object\n",
            "\n",
            "Original text:\n",
            "0    politicians permission needs done\n",
            "Name: English_cleanedText, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWT7WOI6vEJK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}